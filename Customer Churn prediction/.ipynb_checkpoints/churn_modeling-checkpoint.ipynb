{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Churn predictions for Telcom customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "import os\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 21)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Total charges\n",
    "# Replacing spaces with null values in total charges column\n",
    "df['TotalCharges'] = df[\"TotalCharges\"].replace(\" \",np.nan)\n",
    "\n",
    "# Dropping null values from total charges column which contain missing data \n",
    "df = df[df[\"TotalCharges\"].notnull()]\n",
    "df = df.reset_index()[df.columns]\n",
    "\n",
    "# convert to float type\n",
    "df[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)\n",
    "\n",
    "## replace 'No internet service' to No for the following columns\n",
    "replace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                'TechSupport','StreamingTV', 'StreamingMovies']\n",
    "for i in replace_cols : \n",
    "    df[i]  = df[i].replace({'No internet service' : 'No'})\n",
    "    \n",
    "## Senior citizens\n",
    "df[\"SeniorCitizen\"] = df[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n",
    "\n",
    "## Change Churn to Yes or No. \n",
    "churn     = df[df[\"Churn\"] == \"Yes\"]\n",
    "not_churn = df[df[\"Churn\"] == \"No\"]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature processing and Normalization\n",
    "\n",
    "Before model formulation lets convert the Catagorical columns into numeric and some other conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#customer id col and target\n",
    "Id_col     = ['customerID']\n",
    "target_col = [\"Churn\"]\n",
    "\n",
    "## Types of feats. # Segregate the feature types into Numeric, Binayr and Catagorical. \n",
    "\n",
    "#categorical columns\n",
    "cat_cols   = df.nunique()[df.nunique() < 6].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in df.columns if x not in cat_cols + target_col + Id_col]\n",
    "#Binary columns\n",
    "bin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n",
    "#Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "# Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "    \n",
    "# Duplicating columns for multi value columns\n",
    "df = pd.get_dummies(data = df, columns = multi_cols)\n",
    "\n",
    "# Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "# Dropping original values merging scaled values for numerical columns\n",
    "df_telcom_og = df.copy()\n",
    "df = df.drop(columns = num_cols,axis = 1)\n",
    "df = df.merge(scaled,left_index=True,right_index=True,how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 30)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All numeric features: \n",
      " ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
      "Cols with Binary fetures: \n",
      " ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']\n",
      "Cols with multiple fetures: \n",
      " ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod']\n"
     ]
    }
   ],
   "source": [
    "print('All numeric features: \\n', num_cols)\n",
    "print('Cols with Binary fetures: \\n', bin_cols)\n",
    "print('Cols with multiple fetures: \\n', multi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_cols) + len(bin_cols) + len(multi_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols  = [i for i in df.columns if i not in Id_col + target_col]\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train and test data \n",
    "train, test = train_test_split(df, test_size = .25 ,random_state = 666)\n",
    "    \n",
    "# Set training and traget features\n",
    "train_X = train[cols]\n",
    "train_Y = train[target_col]\n",
    "\n",
    "test_X  = test[cols]\n",
    "test_Y  = test[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5274, 28)\n",
      "(5274, 1)\n",
      "(1758, 28)\n",
      "(1758, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit a Logistic model to this. \n",
    "\n",
    "# 'liblinear' handles L1 penalty. \n",
    "logit = LogisticRegression(intercept_scaling=1, max_iter=100, n_jobs=1, penalty='l1', \n",
    "                           random_state=None, solver='liblinear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "logit.fit(train_X, train_Y)\n",
    "preds   = logit.predict(test_X)\n",
    "probs = logit.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64982169, 0.35017831],\n",
       "       [0.72976819, 0.27023181],\n",
       "       [0.93572063, 0.06427937],\n",
       "       ...,\n",
       "       [0.91378859, 0.08621141],\n",
       "       [0.48005385, 0.51994615],\n",
       "       [0.89034471, 0.10965529]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1303\n",
      "           1       0.66      0.48      0.56       455\n",
      "\n",
      "    accuracy                           0.80      1758\n",
      "   macro avg       0.75      0.70      0.71      1758\n",
      "weighted avg       0.79      0.80      0.79      1758\n",
      "\n",
      "Accuracy :  0.800910125142207\n",
      "Area under curve :  0.6969141372825179 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "\n",
    "print(\"Classification report : \\n\",classification_report(test_Y,preds))\n",
    "print (\"Accuracy : \", accuracy_score(test_Y, preds))\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(test_Y, preds)\n",
    "\n",
    "# roc_auc_score\n",
    "model_roc_auc = roc_auc_score(test_Y, preds) \n",
    "\n",
    "print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "fpr,tpr,thresholds = roc_curve(test_Y, probs[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
